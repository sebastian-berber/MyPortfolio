[
  {
    "objectID": "story_telling.html",
    "href": "story_telling.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "story_telling.html#title-2-header",
    "href": "story_telling.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "projects.html",
    "href": "projects.html",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "projects.html#repo-for-all-my-projects",
    "href": "projects.html#repo-for-all-my-projects",
    "title": "DS250 Projects",
    "section": "",
    "text": "Project 1\nProject 2\nProject 3\nProject 4\nProject 5",
    "crumbs": [
      "DS250 Projects"
    ]
  },
  {
    "objectID": "Projects/project4.html",
    "href": "Projects/project4.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#elevator-pitch",
    "href": "Projects/project4.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-1",
    "href": "Projects/project4.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCOPY PASTE QUESTION|TASK 1 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q1 chart .cell execution_count=4}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q1 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=5}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-2",
    "href": "Projects/project4.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q2 chart .cell execution_count=7}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q2 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=8}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project4.html#questiontask-3",
    "href": "Projects/project4.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q3 chart .cell execution_count=10}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q3 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=11}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 4"
    ]
  },
  {
    "objectID": "Projects/project2.html",
    "href": "Projects/project2.html",
    "title": "Client Report - Late flights and Missing Data",
    "section": "",
    "text": "I recived the data from the airports and had to fix it up so I could comfortably analyze the data. I was able to find out the answers to your questions and I found some suprising insights. From the looks of it, the proportions of delays for flights is actually very high. There are various variables or reasons a flight can be delayed but weather has the biggest impact.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_json(\"https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json\")\n\n\n\n\nShow the code\ndef missing_checks(df, column ):\n    out1 = df[column].isnull().sum(axis = 0)\n    out2 = df[column].describe()\n    out3 = df[column].describe(exclude=np.number)\n    print('\\n\\n\\n')\n    print('Checking column' + column)\n    print('\\n')\n    print('Missing summary')\n    print(out1)\n    print('\\n')\n    print(\"Numeric summaries\")\n    print(out2)\n    print('\\n')\n    print('Non Numeric summaries')\n    print(out3)\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#elevator-pitch",
    "href": "Projects/project2.html#elevator-pitch",
    "title": "Client Report - Late flights and Missing Data",
    "section": "",
    "text": "I recived the data from the airports and had to fix it up so I could comfortably analyze the data. I was able to find out the answers to your questions and I found some suprising insights. From the looks of it, the proportions of delays for flights is actually very high. There are various variables or reasons a flight can be delayed but weather has the biggest impact.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_json(\"https://raw.githubusercontent.com/byuidatascience/data4missing/master/data-raw/flights_missing/flights_missing.json\")\n\n\n\n\nShow the code\ndef missing_checks(df, column ):\n    out1 = df[column].isnull().sum(axis = 0)\n    out2 = df[column].describe()\n    out3 = df[column].describe(exclude=np.number)\n    print('\\n\\n\\n')\n    print('Checking column' + column)\n    print('\\n')\n    print('Missing summary')\n    print(out1)\n    print('\\n')\n    print(\"Numeric summaries\")\n    print(out2)\n    print('\\n')\n    print('Non Numeric summaries')\n    print(out3)\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-1",
    "href": "Projects/project2.html#questiontask-1",
    "title": "Client Report - Late flights and Missing Data",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nFix all of the varied missing data types in the data to be consistent (all missing values should be displayed as “NaN”). In your report include one record example (one row) from your new data, in the raw JSON format. Your example should display the “NaN” for at least one missing value.\ntype your results and analysis here\n\n\nShow the code\ndf_clean = df\n\n\n\n\nShow the code\ndf_clean.month.replace(['NaN', 'n/a'], np.nan, inplace = True)\ndf_clean.month.replace('Febuary', 'February', inplace = True)\nmean = round(df_clean.minutes_delayed_carrier.mean(), 2)\ndf_clean.minutes_delayed_carrier.replace(np.nan, mean, inplace = True)\ndf_clean.num_of_delays_late_aircraft.replace(-999, 0, inplace = True)\ndf_clean.num_of_delays_carrier.replace(\"1500+\", 1500, inplace= True)\ndf_clean.airport_name.replace('', 'Washington, DC: Washington Dulles International', inplace = True)\n\ndf_clean.month = df_clean.month.replace('n/a', np.nan)\ndf_clean[\"month\"] = df_clean[\"month\"].ffill()\n\ndf_clean\n\n\n\n\n\n\n\n\n\nairport_code\nairport_name\nmonth\nyear\nnum_of_flights_total\nnum_of_delays_carrier\nnum_of_delays_late_aircraft\nnum_of_delays_nas\nnum_of_delays_security\nnum_of_delays_weather\nnum_of_delays_total\nminutes_delayed_carrier\nminutes_delayed_late_aircraft\nminutes_delayed_nas\nminutes_delayed_security\nminutes_delayed_weather\nminutes_delayed_total\n\n\n\n\n0\nATL\nAtlanta, GA: Hartsfield-Jackson Atlanta Intern...\nJanuary\n2005.0\n35048\n1500\n0\n4598\n10\n448\n8355\n116423.00\n104415\n207467.0\n297\n36931\n465533\n\n\n1\nDEN\nDenver, CO: Denver International\nJanuary\n2005.0\n12687\n1041\n928\n935\n11\n233\n3153\n53537.00\n70301\n36817.0\n363\n21779\n182797\n\n\n2\nIAD\nWashington, DC: Washington Dulles International\nJanuary\n2005.0\n12381\n414\n1058\n895\n4\n61\n2430\n51902.25\n70919\n35660.0\n208\n4497\n134881\n\n\n3\nORD\nChicago, IL: Chicago O'Hare International\nJanuary\n2005.0\n28194\n1197\n2255\n5415\n5\n306\n9178\n88691.00\n160811\n364382.0\n151\n24859\n638894\n\n\n4\nSAN\nSan Diego, CA: San Diego International\nJanuary\n2005.0\n7283\n572\n680\n638\n7\n56\n1952\n27436.00\n38445\n21127.0\n218\n4326\n91552\n\n\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n...\n\n\n919\nIAD\nWashington, DC: Washington Dulles International\nDecember\n2015.0\n2799\n182\n183\n61\n0\n17\n443\n51902.25\n15438\n2826.0\n0\n1825\n31164\n\n\n920\nORD\nChicago, IL: Chicago O'Hare International\nDecember\n2015.0\n25568\n923\n1755\n1364\n11\n180\n4233\n80962.00\n132055\n72045.0\n435\n22459\n307956\n\n\n921\nSAN\nSan Diego, CA: San Diego International\nDecember\n2015.0\n6231\n480\n606\n256\n5\n37\n1383\n25402.00\n35796\n9038.0\n161\n2742\n73139\n\n\n922\nSFO\nSan Francisco, CA: San Francisco International\nDecember\n2015.0\n13833\n757\n1180\n2372\n9\n147\n4465\n55283.00\n96703\n193525.0\n285\n13788\n359584\n\n\n923\nSLC\nSalt Lake City, UT: Salt Lake City International\nDecember\n2015.0\n8804\n483\n796\n404\n5\n56\n1745\n37354.00\n49549\n13515.0\n158\n6693\n107269\n\n\n\n\n924 rows × 17 columns",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-2",
    "href": "Projects/project2.html#questiontask-2",
    "title": "Client Report - Late flights and Missing Data",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nWhich airport has the worst delays? Discuss the metric you chose, and why you chose it to determine the “worst” airport. Your answer should include a summary table that lists (for each airport) the total number of flights, total number of delayed flights, proportion of delayed flights, and average delay time in hours.\nFrom the plots that we have below, I think that everybody hates waiting for delayed flights. I think a good measure of deciding which airport is the ‘worst’ would be to look at the average delay time (in hours) that each delayed flight causes and also the proportion of total flights that are delayed. If we rank these airports based on this criteria, The Chicago O’Hare International (ORD) airport and the San Francisco International (SFO) airport both rank poorly based on these metrics (as they rank both 7th and 8th for both of the metric ranks)\n\n\nRead and format data\n# Include and execute your code here\ndf_clean2 = df_clean\n\ndf_clean2['prop_delayed_flights'] = df_clean2['num_of_delays_total'] / df_clean2['num_of_flights_total']\n\ndf_clean2['avg_delay_hour'] = (df_clean2['minutes_delayed_total'] / df_clean2['num_of_delays_total']) / 60\n\nworst = df_clean2.filter(['airport_code', 'airport_name', 'month', 'year', 'num_of_flights_total', 'num_of_delays_total', 'prop_delayed_flights', 'avg_delay_hour'])\n\nworst.head(10)\n\npx.bar(worst, x = 'airport_code', y =  ['num_of_flights_total', 'num_of_delays_total'], barmode = 'group')\n\nhour = worst.groupby('airport_code')['avg_delay_hour'].mean()\nfig1 = px.bar(hour)\nfig1.update_xaxes(title = \"Airport\")\nfig1.update_yaxes(title = \"Hours\")\nfig1.show()\n\nprop = worst.groupby('airport_code')['prop_delayed_flights'].mean()\nfig2 = px.bar(prop)\nfig2.update_xaxes(title = \"Airport\")\nfig2.update_yaxes(title = \"Proportion of Delayed Flights\")\nfig2.show()\n\n\n# columns_to_calculate = [\n#     ('minutes_delayed_carrier', 'num_of_delays_carrier', 'min/delay_carrier'),\n#     ('minutes_delayed_late_aircraft', 'num_of_delays_late_aircraft', 'min/delay_aircraft'),\n#     ('minutes_delayed_nas', 'num_of_delays_nas', 'min/delay_nas'),\n#     ('minutes_delayed_security', 'num_of_delays_security', 'min/delay_security'),\n#     ('minutes_delayed_weather', 'num_of_delays_weather', 'min/delay_weather'),\n#     ('minutes_delayed_total', 'num_of_delays_total', 'min/delay_total')\n# ]\n\n# for numerator_column, denominator_column, new_column in columns_to_calculate:\n#     df_clean2[new_column] = df_clean2[numerator_column] / df_clean2[denominator_column]",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-3",
    "href": "Projects/project2.html#questiontask-3",
    "title": "Client Report - Late flights and Missing Data",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nWhat is the best month to fly if you want to avoid delays of any length? Discuss the metric you chose and why you chose it to calculate your answer. Include one chart to help support your answer, with the x-axis ordered by month.\nIf you want to avoid any delays in general, I would say to fly in November.The delay data from all of the Novembers are very similar to September but I would say that November barely beats September because of the slightly shorter range.\n\n\nRead and format data\n# Include and execute your code here\ndf_clean3 = df_clean\n\nfig3 = px.box(df_clean3, x = 'month', y = 'prop_delayed_flights', title = \"Proportion of Flight Delays By Month\")\nfig3.update_xaxes(title = 'Months')\nfig3.update_yaxes(title = 'Proportions of Delayed Flights')\nfig3.show()\n\n# Group by 'month' column and calculate summary statistics\nsummary_stats = df_clean3.groupby('month')['prop_delayed_flights'].describe(percentiles=[.25, .5, .75])\n\n# Rename columns for consistency with R's output\nsummary_stats.rename(columns={'25%': 'Q1', '50%': 'med', '75%': 'Q3'}, inplace=True)\n\n# Select the desired summary statistics\nsummary_stats = summary_stats[['min', 'Q1', 'med', 'Q3', 'max']]\n\nprint(summary_stats)\n\n\n                                                \n\n\n                min        Q1       med        Q3       max\nmonth                                                      \nApril      0.080203  0.137128  0.174432  0.213648  0.315318\nAugust     0.100251  0.156416  0.193962  0.227453  0.349593\nDecember   0.103504  0.201211  0.242291  0.305234  0.418206\nFebruary   0.103695  0.163214  0.212048  0.263256  0.393433\nJanuary    0.103338  0.166976  0.208304  0.247575  0.443858\nJuly       0.122160  0.184724  0.221496  0.265193  0.369327\nJune       0.103175  0.201196  0.239995  0.280416  0.395075\nMarch      0.102309  0.161944  0.186357  0.225096  0.375502\nMay        0.075470  0.150902  0.182134  0.227367  0.302933\nNovember   0.059826  0.125181  0.153679  0.196352  0.347786\nOctober    0.068569  0.121447  0.154580  0.210071  0.378300\nSeptember  0.064605  0.119606  0.143640  0.192099  0.364169\n\n\n\n\nShow the code\n# Define the custom ordering of months\n# month_order = ['January', 'February', 'March', 'April', 'May', 'June', 'July', 'August', 'September', 'October', 'November', 'December']\n\n# # Convert the 'month' column to categorical with the custom ordering\n# df['month'] = pd.Categorical(df['month'], categories=month_order, ordered=True)\n\n# # Sort the DataFrame by the 'month' column\n# df_sorted = df.sort_values(by='month')\n\n# print(df_sorted)",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-4",
    "href": "Projects/project2.html#questiontask-4",
    "title": "Client Report - Late flights and Missing Data",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nAccording to the BTS website, the “Weather” category only accounts for severe weather delays. Mild weather delays are not counted in the “Weather” category, but are actually included in both the “NAS” and “Late-Arriving Aircraft” categories. Your job is to create a new column that calculates the total number of flights delayed by weather (both severe and mild). Use these three rules for your calculations:\nA. 100% of delayed flights in the Weather category are due to weather\nB. 30% of all delayed flights in the Late-Arriving category are due to weather.\nC. From April to August, 40% of delayed flights in the NAS category are due to weather. The rest of the months, the proportion rises to 65%.\n\n\nShow the code\n#%%\nflights = df \n\nweather = (flights.assign(\n    severe = flights.num_of_delays_weather, # no missing\n    nodla_nona = lambda x: (x.num_of_delays_late_aircraft\n        .replace(-999, np.nan)), #missing is -999\n    mild_late = lambda x: x.nodla_nona.fillna(x.nodla_nona.mean())*0.3,\n    mild = np.where( # like an if statement\n        flights.month.isin(['April', 'May', 'June', 'July', 'August']), \n            flights.num_of_delays_nas*0.4,\n            flights.num_of_delays_nas*0.65),\n    weather = lambda x: x.severe + x.mild_late + x.mild,\n    proportion_weather_delay = lambda x: x.weather / x.num_of_delays_total,\n    proportion_weather_total = lambda x:  x.weather / x.num_of_flights_total)\n    .filter(['airport_code','month','year', 'severe','mild', 'mild_late',\n    'weather', 'proportion_weather_total', \n    'proportion_weather_delay', 'num_of_flights_total', 'num_of_delays_total']))\nweather.head()\n\n\n\n\n\n\n\n\n\nairport_code\nmonth\nyear\nsevere\nmild\nmild_late\nweather\nproportion_weather_total\nproportion_weather_delay\nnum_of_flights_total\nnum_of_delays_total\n\n\n\n\n0\nATL\nJanuary\n2005.0\n448\n2988.70\n0.0\n3436.70\n0.098057\n0.411335\n35048\n8355\n\n\n1\nDEN\nJanuary\n2005.0\n233\n607.75\n278.4\n1119.15\n0.088212\n0.354948\n12687\n3153\n\n\n2\nIAD\nJanuary\n2005.0\n61\n581.75\n317.4\n960.15\n0.077550\n0.395123\n12381\n2430\n\n\n3\nORD\nJanuary\n2005.0\n306\n3519.75\n676.5\n4502.25\n0.159688\n0.490548\n28194\n9178\n\n\n4\nSAN\nJanuary\n2005.0\n56\n414.70\n204.0\n674.70\n0.092640\n0.345645\n7283\n1952",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "Projects/project2.html#questiontask-5",
    "href": "Projects/project2.html#questiontask-5",
    "title": "Client Report - Late flights and Missing Data",
    "section": "QUESTION|TASK 5",
    "text": "QUESTION|TASK 5\nUsing the new weather variable calculated above, create a barplot showing the proportion of all flights that are delayed by weather at each airport. Discuss what you learn from this graph.\nFrom the looks of it, the smallest mean proportion of delays comes from the San Diego Airport while the largest mean proportion of delays comes from San Francisco. From the looks of it, all of the airports have around 30% of flights dealyed to weather which is a huge proportion if you think about it. That is around 1/3 of all flights total!\n\n\nShow the code\nprop_mean = weather.groupby('airport_code')['proportion_weather_delay'].mean()\n\nfig4 = px.bar(prop_mean, title = \"Mean Proportion of Delays Due To Weather For Each Airport\")\nfig4.update_xaxes(title = \"Airport\")\nfig4.update_yaxes(title = \"Proportion Of Weather Delays\")\n\nfig4.show()\nprop_mean\n\n\n                                                \n\n\nairport_code\nATL    0.337303\nDEN    0.316984\nIAD    0.300992\nORD    0.368703\nSAN    0.278825\nSFO    0.371091\nSLC    0.290117\nName: proportion_weather_delay, dtype: float64",
    "crumbs": [
      "DS250 Projects",
      "Project 2"
    ]
  },
  {
    "objectID": "ml.html",
    "href": "ml.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "ml.html#title-2-header",
    "href": "ml.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html",
    "href": "full_stack.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "full_stack.html#title-2-header",
    "href": "full_stack.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html",
    "href": "competition.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "competition.html#title-2-header",
    "href": "competition.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html",
    "href": "cleansing.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "cleansing.html#title-2-header",
    "href": "cleansing.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html",
    "href": "exploration.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "exploration.html#title-2-header",
    "href": "exploration.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "index.html#title-2-header",
    "href": "index.html#title-2-header",
    "title": "about me",
    "section": "",
    "text": "MarkDown Basics"
  },
  {
    "objectID": "Projects/project1.html",
    "href": "Projects/project1.html",
    "title": "Client Report - What’s in a Name?",
    "section": "",
    "text": "From the data that I was given, I was able to find some facinating inferences about the data. I was able to see that my name Sebastian started to become popular after the year 2000. I also wanted to see if there was any influence on the name Luke during the time that Star Wars was recently released. I found that the years after, the name did seem to become poplar.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#elevator-pitch",
    "href": "Projects/project1.html#elevator-pitch",
    "title": "Client Report - What’s in a Name?",
    "section": "",
    "text": "From the data that I was given, I was able to find some facinating inferences about the data. I was able to see that my name Sebastian started to become popular after the year 2000. I also wanted to see if there was any influence on the name Luke during the time that Star Wars was recently released. I found that the years after, the name did seem to become poplar.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-1",
    "href": "Projects/project1.html#questiontask-1",
    "title": "Client Report - What’s in a Name?",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nHow does your name at your birth year compare to its use historically?\nHistorically speaking, The name sebastian dropped after the year 2002 but later peaked again in 2006 and continued to have an increase in frequency the following years. The name seemed to start to become popular after the year 2000.\n\n\nRead and format data\n# Include and execute your code here\ndata_sebastian = df.query(\"name == 'Sebastian'\")\n\nfig = px.bar(data_sebastian,\n    x = \"year\",\n    y = \"Total\",\n    title = \"Babies Named Sebastian by Year\")\n\nfig.update_xaxes(range=[1970, 2016],\n                 title_text='Year (1970-2015)')\nfig.update_yaxes(title_text='Frequency')\n\nfig.update_layout(\n    shapes=[\n        dict(\n            type='line',\n            x0=2002,\n            x1=2002,\n            y0=10000,\n            y1=max(data_sebastian['AK']),  # Adjust the y-coordinate range as needed\n            line=dict(color='red', width=2)\n        )\n    ]\n)\n\nfig.update_layout(\n    annotations=[\n        dict(\n            x=1995,  # X-coordinate of the annotation\n            y=9000,  # Y-coordinate of the annotation\n            text='Year I was born (2002)',\n            showarrow=False\n        )\n    ]\n)",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-2",
    "href": "Projects/project1.html#questiontask-2",
    "title": "Client Report - What’s in a Name?",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nIf you talked to someone named Brittany on the phone, what is your guess of his or her age? What ages would you not guess?\nWell from the look of the graph, The name Brittany peaked in the year 1990 and it had 32,000 babies named Brittany that year. So I would guess that her age would’ve been 34. I would not guess her age to be 40 or older neither 25 or younger becuase those would be the ages of when Brittany was starting to become popular and when the name was starting to become less popular.\n\n\nRead and format data\n# Include and execute your code here\ndata_brittany = df.query(\"name == 'Brittany'\") \n\nfig = px.bar(data_brittany,\n    x = \"year\",\n    y = \"Total\",\n    title = \"Babies named Brittany by Birth Year\")\n\nfig.update_xaxes(range=[1970, 2016],\n                 title_text='Year (1970-2015)')\nfig.update_yaxes(title_text='Frequency')\n\nfig.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-3",
    "href": "Projects/project1.html#questiontask-3",
    "title": "Client Report - What’s in a Name?",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nMary, Martha, Peter, and Paul are all Christian names. From 1920 - 2000, compare the name usage of each of the four names. What trends do you notice?\nWell, from the graph, I can tell that the name trends became popular between 1940 and 1960. Mary had a huge portion of the trend but they all peacked between those times.\n\n\nRead and format data\n# Include and execute your code here\nselected_names = ['Mary', 'Martha', 'Peter', 'Paul']\nfiltered_df = df[(df['name'].isin(selected_names))]\n\nfiltered_df1 = px.bar(filtered_df,\n    x = \"year\",\n    y = \"Total\",\n    color = \"name\",\n    title = \"Chistian Names By Year\")\n\nfiltered_df1.update_xaxes(range=[1920, 2000],\n                          title = \"Year (1920-2000)\")\n\nfiltered_df1.update_yaxes(title = \"Frequency\")\n\nfiltered_df1",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project1.html#questiontask-4",
    "href": "Projects/project1.html#questiontask-4",
    "title": "Client Report - What’s in a Name?",
    "section": "QUESTION|TASK 4",
    "text": "QUESTION|TASK 4\nThink of a unique name from a famous movie. Plot the usage of that name and see how changes line up with the movie release. Does it look like the movie had an effect on usage?\nI waned to see how the name Luke increased after the Star Wars Saga was introduced. Star Wars is arguably one of the most famous movie series that has ever come out. Below shows the trend of the name and the lines are the release years of the 3 movies.\n\n\nRead and format data\n# Include and execute your code here\n\nname_luke = df.query(\"name == 'Luke'\")\n\nfig = px.bar(name_luke,\n    x = \"year\",\n    y = \"Total\",\n    title = \"Is The Name Luke Related to Star Wars\")\n\n\nfig.update_xaxes(range=[1975, 2015],\n                 title = \"Year (1975-2015)\")\nfig.update_yaxes(title = \"Frequency\")\nfig.update_layout(\n    shapes=[\n        dict(\n            type='line',\n            yref='paper',\n            y0=0,\n            y1=1,\n            xref='x',\n            x0='1977',\n            x1='1977',\n            line=dict(color='yellow'),\n        ),\n        dict(\n            type='line',\n            yref='paper',\n            y0=0,\n            y1=1,\n            xref='x',\n            x0='1980',\n            x1='1980',\n            line=dict(color='red'),\n        ),\n        dict(\n            type='line',\n            yref='paper',\n            y0=0,\n            y1=1,\n            xref='x',\n            x0='1983',\n            x1='1983',\n            line=dict(color='green'),\n        )\n    ],\n)\n\nfig.show()",
    "crumbs": [
      "DS250 Projects",
      "Project 1"
    ]
  },
  {
    "objectID": "Projects/project3.html",
    "href": "Projects/project3.html",
    "title": "Client Report - Finding relationships in baseball",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\n\nsqlite_file = 'lahmansbaseballdb.sqlite'\ncon = sqlite3.connect(sqlite_file)",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#elevator-pitch",
    "href": "Projects/project3.html#elevator-pitch",
    "title": "Client Report - Finding relationships in baseball",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\n\nsqlite_file = 'lahmansbaseballdb.sqlite'\ncon = sqlite3.connect(sqlite_file)",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-1",
    "href": "Projects/project3.html#questiontask-1",
    "title": "Client Report - Finding relationships in baseball",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nWrite an SQL query to create a new dataframe about baseball players who attended BYU-Idaho. The new table should contain five columns: playerID, schoolID, salary, and the yearID/teamID associated with each salary. Order the table by salary (highest to lowest) and print out the table in your report.\n\n\nRead and format data\n# Include and execute your code here\n\nq = '''\n    SELECT p.playerID\n    ,      cp.schoolID\n    ,      salary\n    ,      s.yearID\n    ,      s.teamID\n    FROM people p\n    LEFT JOIN collegeplaying cp\n      ON cp.playerID = p.playerID\n    INNER JOIN schools sc\n      ON sc.schoolID = cp.schoolID\n    LEFT JOIN salaries s\n      ON p.playerID = s.playerID\n    WHERE cp.schoolID = 'idbyuid'\n    ORDER BY salary DESC\n'''\n# comment\nresults1 = pd.read_sql_query(q, con)\n\nresults1\n\n\n\n\n\n\n\n\n\nplayerID\nschoolID\nsalary\nyearID\nteamID\n\n\n\n\n0\nlindsma01\nidbyuid\n4000000.0\n2014.0\nCHA\n\n\n1\nlindsma01\nidbyuid\n4000000.0\n2014.0\nCHA\n\n\n2\nlindsma01\nidbyuid\n3600000.0\n2012.0\nBAL\n\n\n3\nlindsma01\nidbyuid\n3600000.0\n2012.0\nBAL\n\n\n4\nlindsma01\nidbyuid\n2800000.0\n2011.0\nCOL\n\n\n5\nlindsma01\nidbyuid\n2800000.0\n2011.0\nCOL\n\n\n6\nlindsma01\nidbyuid\n2300000.0\n2013.0\nCHA\n\n\n7\nlindsma01\nidbyuid\n2300000.0\n2013.0\nCHA\n\n\n8\nlindsma01\nidbyuid\n1625000.0\n2010.0\nHOU\n\n\n9\nlindsma01\nidbyuid\n1625000.0\n2010.0\nHOU\n\n\n10\nstephga01\nidbyuid\n1025000.0\n2001.0\nSLN\n\n\n11\nstephga01\nidbyuid\n1025000.0\n2001.0\nSLN\n\n\n12\nstephga01\nidbyuid\n900000.0\n2002.0\nSLN\n\n\n13\nstephga01\nidbyuid\n900000.0\n2002.0\nSLN\n\n\n14\nstephga01\nidbyuid\n800000.0\n2003.0\nSLN\n\n\n15\nstephga01\nidbyuid\n800000.0\n2003.0\nSLN\n\n\n16\nstephga01\nidbyuid\n550000.0\n2000.0\nSLN\n\n\n17\nstephga01\nidbyuid\n550000.0\n2000.0\nSLN\n\n\n18\nlindsma01\nidbyuid\n410000.0\n2009.0\nFLO\n\n\n19\nlindsma01\nidbyuid\n410000.0\n2009.0\nFLO\n\n\n20\nlindsma01\nidbyuid\n395000.0\n2008.0\nFLO\n\n\n21\nlindsma01\nidbyuid\n395000.0\n2008.0\nFLO\n\n\n22\nlindsma01\nidbyuid\n380000.0\n2007.0\nFLO\n\n\n23\nlindsma01\nidbyuid\n380000.0\n2007.0\nFLO\n\n\n24\nstephga01\nidbyuid\n215000.0\n1999.0\nSLN\n\n\n25\nstephga01\nidbyuid\n215000.0\n1999.0\nSLN\n\n\n26\nstephga01\nidbyuid\n185000.0\n1998.0\nPHI\n\n\n27\nstephga01\nidbyuid\n185000.0\n1998.0\nPHI\n\n\n28\nstephga01\nidbyuid\n150000.0\n1997.0\nPHI\n\n\n29\nstephga01\nidbyuid\n150000.0\n1997.0\nPHI\n\n\n30\ncatetr01\nidbyuid\nNaN\nNaN\nNone",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-2",
    "href": "Projects/project3.html#questiontask-2",
    "title": "Client Report - Finding relationships in baseball",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nThis three-part question requires you to calculate batting average (number of hits divided by the number of at-bats)\na. Write an SQL query that provides playerID, yearID, and batting average for players with at least 1 at bat that year. Sort the table from highest batting average to lowest, and then by playerid alphabetically. Show the top 5 results in your report.\n\n\nRead and format data\n# Include and execute your code here\n\nq = '''\n    SELECT playerID\n    ,      yearID\n    ,      ((1.0 * H) / AB) AS 'Batting_Average'\n    FROM batting\n    WHERE AB &gt;= 1\n    ORDER BY Batting_Average DESC, playerid\n    LIMIT 5\n'''\n\nresults2 = pd.read_sql_query(q, con)\n\nresults2\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nBatting_Average\n\n\n\n\n0\naberal01\n1957\n1.0\n\n\n1\nabernte02\n1960\n1.0\n\n\n2\nabramge01\n1923\n1.0\n\n\n3\nacklefr01\n1964\n1.0\n\n\n4\nalanirj01\n2019\n1.0\n\n\n\n\n\n\n\nb. Use the same query as above, but only include players with at least 10 at bats that year. Print the top 5 results.\n\n\nRead and format data\n# Include and execute your code here\n\nq = '''\n    SELECT playerID\n    ,      yearID\n    ,      ((1.0 * H) / AB) AS 'Batting_Average'\n    FROM batting\n    WHERE AB &gt;= 10\n    ORDER BY Batting_Average DESC, playerid\n    LIMIT 5\n'''\n\nresults3 = pd.read_sql_query(q, con)\n\nresults3\n\n\n\n\n\n\n\n\n\nplayerID\nyearID\nBatting_Average\n\n\n\n\n0\nnymanny01\n1974\n0.642857\n\n\n1\ncarsoma01\n2013\n0.636364\n\n\n2\naltizda01\n1910\n0.600000\n\n\n3\njohnsde01\n1975\n0.600000\n\n\n4\nsilvech01\n1948\n0.571429\n\n\n\n\n\n\n\nc. Now calculate the batting average for players over their entire careers (all years combined). Only include players with at least 100 at bats, and print the top 5 results.\n\n\nRead and format data\n# Include and execute your code here\n\nq = '''\n    SELECT playerID\n    ,      SUM(H) AS 'Total_Hits'\n    ,      SUM(AB) AS 'Total_At_Bats'\n    ,      ((SUM(H) * 1.0) / SUM(AB)) AS 'Batting_Average'\n    FROM batting\n    WHERE AB &gt;= 100\n    GROUP BY playerID\n'''\n\nresults3 = pd.read_sql_query(q, con)\n\nresults3\n\n\n\n\n\n\n\n\n\nplayerID\nTotal_Hits\nTotal_At_Bats\nBatting_Average\n\n\n\n\n0\naaronha01\n3771\n12364\n0.304998\n\n\n1\naaronto01\n173\n752\n0.230053\n\n\n2\nabbated01\n728\n2852\n0.255259\n\n\n3\nabbeych01\n493\n1756\n0.280752\n\n\n4\nabbotfr01\n107\n513\n0.208577\n\n\n...\n...\n...\n...\n...\n\n\n7035\nzuletju01\n23\n106\n0.216981\n\n\n7036\nzuninmi01\n435\n2151\n0.202232\n\n\n7037\nzupcibo01\n177\n678\n0.261062\n\n\n7038\nzuvelpa01\n78\n320\n0.243750\n\n\n7039\nzwilldu01\n342\n1140\n0.300000\n\n\n\n\n7040 rows × 4 columns",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project3.html#questiontask-3",
    "href": "Projects/project3.html#questiontask-3",
    "title": "Client Report - Finding relationships in baseball",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nPick any two baseball teams and compare them using a metric of your choice (average salary, home runs, number of wins, etc). Write an SQL query to get the data you need, then make a graph using Plotly Express to visualize the comparison. What do you learn?\n\n\nRead and format data\n# Include and execute your code here\n\nq = '''\n    SELECT name\n    ,      SUM(W) AS 'Wins'\n    ,      SUM(G) AS 'Total Games'\n    ,      (SUM(W) / (SUM(G) * 1.0)) AS \"Win_Rate\"\n    FROM teams\n    WHERE name IN ('New York Giants', 'Boston Red Sox')\n    GROUP BY name\n\n'''\nresults4 = pd.read_sql_query(q, con)\n\nresults4\n\n\n\n\n\n\n\n\n\nname\nWins\nTotal Games\nWin_Rate\n\n\n\n\n0\nBoston Red Sox\n9074\n17556\n0.516860\n\n\n1\nNew York Giants\n6033\n11033\n0.546814",
    "crumbs": [
      "DS250 Projects",
      "Project 3"
    ]
  },
  {
    "objectID": "Projects/project5.html",
    "href": "Projects/project5.html",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#elevator-pitch",
    "href": "Projects/project5.html#elevator-pitch",
    "title": "Client Report - [Insert Project Title]",
    "section": "",
    "text": "paste your elevator pitch here A SHORT (4-5 SENTENCES) PARAGRAPH THAT DESCRIBES KEY INSIGHTS TAKEN FROM METRICS IN THE PROJECT RESULTS THINK TOP OR MOST IMPORTANT RESULTS.\n\n\nRead and format project data\n# Include and execute your code here\ndf = pd.read_csv(\"https://github.com/byuidatascience/data4names/raw/master/data-raw/names_year/names_year.csv\")\n\n\nHighlight the Questions and Tasks",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-1",
    "href": "Projects/project5.html#questiontask-1",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 1",
    "text": "QUESTION|TASK 1\nCOPY PASTE QUESTION|TASK 1 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q1 chart .cell execution_count=4}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q1 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=5}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-2",
    "href": "Projects/project5.html#questiontask-2",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 2",
    "text": "QUESTION|TASK 2\nCOPY PASTE QUESTION|TASK 2 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q2 chart .cell execution_count=7}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q2 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=8}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Projects/project5.html#questiontask-3",
    "href": "Projects/project5.html#questiontask-3",
    "title": "Client Report - [Insert Project Title]",
    "section": "QUESTION|TASK 3",
    "text": "QUESTION|TASK 3\nCOPY PASTE QUESTION|TASK 3 FROM THE PROJECT HERE\ntype your results and analysis here\n\n\nRead and format data\n# Include and execute your code here\n\n\ninclude figures in chunks and discuss your findings in the figure.\n::: {#cell-Q3 chart .cell execution_count=10}\n\nplot example\n# Include and execute your code here\nchart = px.bar(df.head(200),\n    x=\"name\", \n    y=\"AK\"\n)\nchart.show()\n\n\n                                                \nMy useless chart\n\n:::\n::: {#cell-Q3 table .cell .tbl-cap-location-top tbl-cap=‘Not much of a table’ execution_count=11}\n\ntable example\n# Include and execute your code here\nmydat = df.head(1000)\\\n    .groupby('year')\\\n    .sum()\\\n    .reset_index()\\\n    .tail(10)\\\n    .filter([\"year\", \"AK\",\"AR\"])\n\ndisplay(mydat)\n\n\n\n\n\n\n\n\n\nyear\nAK\nAR\n\n\n\n\n96\n2006\n21.0\n183.0\n\n\n97\n2007\n28.0\n153.0\n\n\n98\n2008\n36.0\n212.0\n\n\n99\n2009\n34.0\n179.0\n\n\n100\n2010\n22.0\n196.0\n\n\n101\n2011\n41.0\n148.0\n\n\n102\n2012\n28.0\n140.0\n\n\n103\n2013\n26.0\n134.0\n\n\n104\n2014\n20.0\n114.0\n\n\n105\n2015\n28.0\n121.0\n\n\n\n\n\n\n:::",
    "crumbs": [
      "DS250 Projects",
      "Project 5"
    ]
  },
  {
    "objectID": "Resume.html",
    "href": "Resume.html",
    "title": "Sebastian Berber Resume",
    "section": "",
    "text": "Highly motivated and skilled individual with a diverse work history, seeking employment to save money for college. Experienced in various roles, including irrigation repair, customer service, technical support, and food delivery. Committed to providing exceptional service, demonstrating a strong work ethic, and achieving customer satisfaction"
  },
  {
    "objectID": "Resume.html#objective",
    "href": "Resume.html#objective",
    "title": "Sebastian Berber Resume",
    "section": "",
    "text": "Highly motivated and skilled individual with a diverse work history, seeking employment to save money for college. Experienced in various roles, including irrigation repair, customer service, technical support, and food delivery. Committed to providing exceptional service, demonstrating a strong work ethic, and achieving customer satisfaction"
  },
  {
    "objectID": "Resume.html#skills",
    "href": "Resume.html#skills",
    "title": "Sebastian Berber Resume",
    "section": "Skills",
    "text": "Skills\n• Strong problem-solving and analytical abilities.\n• Excellent customer service and communication skills.\n• Proficient in computer repair and maintenance.\n• Bilingual fluency in English and Spanish (written and spoken).\n• Efficient and dependable, delivering results in a timely manner.\n• Ability to work independently and as part of a team"
  },
  {
    "objectID": "Resume.html#education",
    "href": "Resume.html#education",
    "title": "Sebastian Berber Resume",
    "section": "Education:",
    "text": "Education:\n• High School Diploma (year graduated: 2020)\n  Liberty Hill High School, Liberty Hill, Texas\n• Bachelor's Degree in Data Science (expected completion: 2027)\n  Brigham Young University-Idaho, Rexburg, Idaho"
  },
  {
    "objectID": "Resume.html#pressure-washing-technician-binney-and-the-jets-liberty-hill-texas-may-2023---present",
    "href": "Resume.html#pressure-washing-technician-binney-and-the-jets-liberty-hill-texas-may-2023---present",
    "title": "Sebastian Berber Resume",
    "section": "Pressure Washing Technician, Binney and the Jets [Liberty Hill, Texas] May 2023 - Present",
    "text": "Pressure Washing Technician, Binney and the Jets [Liberty Hill, Texas] May 2023 - Present\n• Successfully pressure washed commercial vehicles and waste receptacles, maintaining their cleanliness\n  and appearance.\n• Operated company truck, pulling the water tank and pressure washing trailer, ensuring efficient\n  completion of tasks.\n• Conducted equipment maintenance and repairs to maximize performance and minimize downtime."
  },
  {
    "objectID": "Resume.html#volunteer-service-states-massachusetts-connecticut-rhode-island-april-2021---may-2023",
    "href": "Resume.html#volunteer-service-states-massachusetts-connecticut-rhode-island-april-2021---may-2023",
    "title": "Sebastian Berber Resume",
    "section": "Volunteer Service, [States: Massachusetts, Connecticut, Rhode Island] April 2021 - May 2023",
    "text": "Volunteer Service, [States: Massachusetts, Connecticut, Rhode Island] April 2021 - May 2023\n• Engaged directly with the public through social media and face-to-face meetings.\n• Taught English speaking classes to non-English speakers, sharing language skills and promoting education.\n• Volunteered at food banks and soup kitchens, serving the community in need.\n• Served as a trainer for new missionaries and District Leader, providing training and guidance to other\n  missionaries."
  },
  {
    "objectID": "Resume.html#independent-contractor-door-dash-austin-texas-april-2021---may-2023",
    "href": "Resume.html#independent-contractor-door-dash-austin-texas-april-2021---may-2023",
    "title": "Sebastian Berber Resume",
    "section": "Independent Contractor, Door Dash, [Austin, Texas] April 2021 - May 2023",
    "text": "Independent Contractor, Door Dash, [Austin, Texas] April 2021 - May 2023\n• Delivered food orders promptly, providing excellent customer service and achieving substantial tips.\n• Demonstrated adaptability and efficiency in a fast-paced, customer-focused environment.\n• Maintained professionalism and ensured customer satisfaction."
  },
  {
    "objectID": "Resume.html#food-service-team-member-whataburger-cedar-park-texas-april-2020---march-2021",
    "href": "Resume.html#food-service-team-member-whataburger-cedar-park-texas-april-2020---march-2021",
    "title": "Sebastian Berber Resume",
    "section": "Food Service Team Member, Whataburger, [Cedar Park, Texas] April 2020 - March 2021",
    "text": "Food Service Team Member, Whataburger, [Cedar Park, Texas] April 2020 - March 2021\n• Took customer food orders with accuracy and efficiency.\n• Demonstrated versatility by excelling in working at various food prep stations.\n• Maintained cleanliness and organization in work areas to meet quality standards.\n• Consistently delivered exceptional customer service, ensuring customer satisfaction and fostering positive\n  interactions and a positive dining experience.\n• Received positive feedback from the employer for being dependable, hardworking, and displaying a\n  positive attitude.\n• Collaborated with team members to ensure smooth workflow and efficient operations."
  },
  {
    "objectID": "Resume.html#computer-technician-intern-praxitek-llc-cedar-park-texas-march-2020---april-2020",
    "href": "Resume.html#computer-technician-intern-praxitek-llc-cedar-park-texas-march-2020---april-2020",
    "title": "Sebastian Berber Resume",
    "section": "Computer Technician Intern, PraxiTek LLC [Cedar Park, Texas] March 2020 - April 2020",
    "text": "Computer Technician Intern, PraxiTek LLC [Cedar Park, Texas] March 2020 - April 2020\n• Assisted senior technician in stripping, disassembling, and disposing of old computers.\n• Conducted hard drive data sanitization and basic PC repairs under supervision.\n• Participated in CAT 6 cable installation and performed basic equipment maintenance tasks."
  },
  {
    "objectID": "Resume.html#irrigation-repair-technician-ondemand-sprinklers-liberty-hill-texas-june-2019---august-2019",
    "href": "Resume.html#irrigation-repair-technician-ondemand-sprinklers-liberty-hill-texas-june-2019---august-2019",
    "title": "Sebastian Berber Resume",
    "section": "Irrigation Repair Technician, OnDemand Sprinklers [Liberty Hill, Texas] June 2019 - August 2019",
    "text": "Irrigation Repair Technician, OnDemand Sprinklers [Liberty Hill, Texas] June 2019 - August 2019\n• Conducted pipe and sprinkler repairs, ensuring efficient and effective irrigation systems.\n• Programmed sprinkler systems to meet specific client requirements and optimize water usage.\n• Successfully couriered parts for management and other teams, ensuring seamless operations.\n• Demonstrated professionalism and courtesy when interacting with customers, providing excellent service.\n• Received consistent feedback from employer highlighting my speed, efficiency, and dep\nMarkDown Basics"
  }
]